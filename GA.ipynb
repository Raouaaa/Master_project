{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn.svm\n",
    "#from GA import GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=sio.loadmat('./intermediate/Feature_vectors.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Data['Features_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[~np.all(X == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=sio.loadmat('./labels77.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=labels['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape    # number of samples and number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 5 folds\n",
    "kf5=KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fea = [i for i in range(10,110,10)]\n",
    "clf = svm.LinearSVC()    # linear SVM\n",
    "correct=0\n",
    "accuracy=[]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def GA_FS():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 589)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=clf, n_features_to_select=5, step=1)\n",
    "#rfe = rfe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "featureranking=[]\n",
    "correct=0\n",
    "for train_index, test_index in kf5.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=5, step=1)\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "    #print('Chosen best 5 feature by rfe:',X_train.columns[rfe.support_])\n",
    "    print(X_train[[rfe.support_]])\n",
    "    \n",
    "    #selected_features = X[:, idx[0:k]]\n",
    "    #featureranking.extend([idx])\n",
    "    # train a classification model with the selected features on the training dataset\n",
    "    #clf.fit(selected_features[train_index], y[train_index])  # predict the class labels of test data\n",
    "    #y_predict = clf.predict(selected_features[test_index])\n",
    "    # obtain the classification accuracy on the test data\n",
    "    #acc = accuracy_score(y[test_index], y_predict)\n",
    "    #correct = correct + acc\n",
    "    # output the average classification accuracy over all folds\n",
    "#accuracy=float(correct)/cv.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "rfecv = RFECV(estimator=clf, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\n",
    "rfecv = rfecv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6776470588235294"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.grid_scores_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfecv_FS(cv,X_train,y_train):\n",
    "    rfecv = RFECV(estimator=clf, step=1, cv=cv.get_n_splits(X),scoring='accuracy')   #5-fold cross-validation\n",
    "    rfecv = rfecv.fit(X_train, y_train)\n",
    "    idx=rfecv.ranking_\n",
    "    return(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureranking=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf5.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    idx=rfecv_FS(kf5,X_train,y_train)\n",
    "    selected_features = X[:, idx[0:10]]\n",
    "    featureranking.extend([idx])\n",
    "\n",
    "    # train a classification model with the selected features on the training dataset\n",
    "    clf.fit(selected_features[train_index], y[train_index])  # predict the class labels of test data\n",
    "    y_predict = clf.predict(selected_features[test_index])\n",
    "    # obtain the classification accuracy on the test data\n",
    "    acc = accuracy_score(y[test_index], y_predict)\n",
    "    correct = correct + acc\n",
    "\n",
    "    # output the average classification accuracy over all folds\n",
    "accuracy=float(correct)/kf5.get_n_splits(X)\n",
    "    #return(np.array(featureranking),accuracy)\n",
    "    #print('Optimal number of features :', rfecv.n_features_)\n",
    "    #print('Best features :', X_train[[rfecv.support_]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice=np.array(featureranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6266666666666667"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 589)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFS backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_selector = SequentialFeatureSelector(clf,\n",
    "           k_features=589,\n",
    "           forward=True,\n",
    "           verbose=2,\n",
    "           scoring='roc_auc',\n",
    "           cv=4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features.subsets_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features = feature_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS via gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "all_comb = []\n",
    "for size in range(1, 5):\n",
    "    all_comb += list(combinations(range(X.shape[1]), r=size))\n",
    "print(all_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import ColumnSelector\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     ColumnSelector(),\n",
    "                     clf)\n",
    "# Optimal parameters for SVM using gridsearch\n",
    "param_grid = {'columnselector__cols': all_comb}\n",
    "#param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}\n",
    "\n",
    "grid = GridSearchCV(clf,param_grid,cv=5,n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "#print('Best parameters:', grid.best_params_)\n",
    "#print('Best performance:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cv,k,FS_method):\n",
    "    accuracy=[]\n",
    "    featureranking=[]\n",
    "    correct=0\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        if FS_method==reliefF:\n",
    "            idx=GA_FS(X_train,y_train)\n",
    "  \n",
    "        selected_features = X[:, idx[0:k]]\n",
    "        featureranking.extend([idx])\n",
    "\n",
    "        # train a classification model with the selected features on the training dataset\n",
    "        clf.fit(selected_features[train_index], y[train_index])  # predict the class labels of test data\n",
    "        y_predict = clf.predict(selected_features[test_index])\n",
    "        # obtain the classification accuracy on the test data\n",
    "        acc = accuracy_score(y[test_index], y_predict)\n",
    "        correct = correct + acc\n",
    "\n",
    "        # output the average classification accuracy over all folds\n",
    "    accuracy=float(correct)/cv.get_n_splits(X)\n",
    "    return(np.array(featureranking),accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============Main=============================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
